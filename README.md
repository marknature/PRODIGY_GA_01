# Task-01 ProDigy infotech 
### Text Generation with GPT-2 ğŸ­ğŸŒ±

Train a model to generate coherent and contextually relevant text based on a given prompt. Starting with GPT-2, a transformer model developed by OpenAI, you will learn how to fine-tune the model on a custom dataset to create text that mimics the style and structure of your training data. 
Ref:
1. https://huggingface.co/blog/how-to-generate
2. https://colab.research.google.com/drive/15qBZx5y9rdaQSyWpsreMDnTiZ5IlN0zD?usp=sharing

#### PRODIGY_GA_01
"For Generative AI Interns, focus on learning the topics and understanding the theory in as much detail as possible. The output doesnâ€™t matter if you donâ€™t grasp the theory behind these complex topics."
