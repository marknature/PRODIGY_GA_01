# Task-01 ProDigy infotech 
### Text Generation with GPT-2 🍭🌱

Train a model to generate coherent and contextually relevant text based on a given prompt. Starting with GPT-2, a transformer model developed by OpenAI, you will learn how to fine-tune the model on a custom dataset to create text that mimics the style and structure of your training data. 
Ref:
1. https://huggingface.co/blog/how-to-generate
2. https://colab.research.google.com/drive/15qBZx5y9rdaQSyWpsreMDnTiZ5IlN0zD?usp=sharing

#### PRODIGY_GA_01
"For Generative AI Interns, focus on learning the topics and understanding the theory in as much detail as possible. The output doesn’t matter if you don’t grasp the theory behind these complex topics."
